# VoiceTranslate Pro - Agent Documentation

> **For AI Coding Agents**: This document provides essential context for working with this codebase. The information is based on actual project files and structure.

---

## Project Overview

**VoiceTranslate Pro** (also known as pyLiveTranslator) is a production-ready real-time voice translation application featuring streaming translation with draft/final modes. Version 2.0.0+ supports English, Chinese (Simplified/Traditional), Japanese, and French with hardware acceleration and Docker deployment.

### Key Capabilities

- ğŸ¤ **Streaming Translation** - Draft previews every 2s, final translation on silence
- ğŸ”„ **Multi-Language** - EN, ZH, JA with optimized MarianMT models
- âš¡ **Low Latency** - TTFT ~1.5s, Meaning Latency ~1.8s
- ğŸ›ï¸ **Multiple Modes** - Standard, Interview (documentary), Sentence modes
- ğŸ™ï¸ **Mic Selection** - GUI dropdown + CLI support
- ğŸ³ **Docker Ready** - Production deployment with Prometheus/Grafana
- ğŸ–¥ï¸ **Cross-Platform** - Windows, macOS (Apple Silicon optimized), Linux

### Target Platforms

| Platform | Status | Notes |
|----------|--------|-------|
| macOS 11+ | âœ… Fully Supported | Apple Silicon M1/M2/M3 optimized (MPS backend) |
| Windows 10/11 | âœ… Fully Supported | x86_64 with CUDA/OpenVINO support |
| Linux | âœ… Supported | Primary for Docker deployment |

### Supported Languages

| Language | Code | ASR | Translation | Quality |
|----------|------|-----|-------------|---------|
| English | en | âœ… | âœ… | Excellent |
| Chinese (Simplified) | zh | âœ… | âœ… | Good |
| Chinese (Traditional) | zh-TW | âœ… | âœ… | Good |
| Japanese | ja | âœ… | âœ… | Good |
| French | fr | âœ… | âœ… | Good |

---

## Technology Stack

| Component | Technology | Version/Notes |
|-----------|------------|---------------|
| **Language** | Python | 3.9+ required, 3.11 recommended |
| **GUI Framework** | PySide6 | Qt-based GUI |
| **ASR** | faster-whisper | CTranslate2 backend, int8 quantization |
| **ASR (Apple)** | mlx-whisper | Apple Silicon optimized |
| **Translation** | MarianMT | Helsinki-NLP models |
| **VAD** | Silero VAD v5.1 | Primary voice detection |
| **VAD (Fallback)** | WebRTC VAD | Lightweight alternative |
| **Audio I/O** | sounddevice, PyAudio | PortAudio backend |
| **System Audio** | pyaudiowpatch (Win), BlackHole (macOS) | Loopback capture |
| **ML Framework** | PyTorch 2.0+ | MPS (Apple) / CUDA (NVIDIA) |
| **Hardware Opt** | OpenVINO, CoreML | Intel/Apple acceleration |
| **Backend API** | FastAPI | Optional REST API |
| **Monitoring** | Prometheus, Grafana | Metrics and dashboards |
| **Testing** | pytest | Unit and integration tests |

### Translation Models

| Pair | Model | Size |
|------|-------|------|
| zh â†’ en | Helsinki-NLP/opus-mt-zh-en | ~400MB |
| en â†’ zh | Helsinki-NLP/opus-mt-en-zh | ~400MB |
| ja â†’ en | Helsinki-NLP/opus-mt-ja-en | ~400MB |
| en â†’ ja | Helsinki-NLP/opus-mt-en-ja | ~400MB |

---

## Project Structure

```
pyLiveTranslator_kimi/
â”œâ”€â”€ README.md                    # Main project documentation
â”œâ”€â”€ STATUS.md                    # Development status and phases
â”œâ”€â”€ AGENTS.md                    # This file - AI agent documentation
â”œâ”€â”€ FINAL_IMPLEMENTATION_SUMMARY.md  # Complete feature summary
â”œâ”€â”€ SENTENCE_MODE_GUIDE.md       # Sentence mode documentation
â”œâ”€â”€ JAPANESE_TRANSLATION_GUIDE.md    # Japanese translation guide
â”œâ”€â”€ SPEECH_LOSS_EVALUATION_GUIDE.md  # Speech loss evaluation
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/                    # Core translation engine
â”‚   â”‚   â”œâ”€â”€ asr/                 # Automatic Speech Recognition
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”œâ”€â”€ faster_whisper.py      # Primary ASR (faster-whisper)
â”‚   â”‚   â”‚   â”œâ”€â”€ mlx_whisper.py         # Apple Silicon ASR
â”‚   â”‚   â”‚   â”œâ”€â”€ whisper_cpp.py
â”‚   â”‚   â”‚   â”œâ”€â”€ streaming_asr.py       # Draft/final streaming modes
â”‚   â”‚   â”‚   â”œâ”€â”€ post_processor.py      # Hallucination filter (CJK-aware)
â”‚   â”‚   â”‚   â””â”€â”€ hardware_backends.py   # OpenVINO/CoreML backends
â”‚   â”‚   â”œâ”€â”€ pipeline/            # Translation pipelines
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”œâ”€â”€ realtime.py
â”‚   â”‚   â”‚   â”œâ”€â”€ batch.py
â”‚   â”‚   â”‚   â”œâ”€â”€ hybrid.py
â”‚   â”‚   â”‚   â”œâ”€â”€ orchestrator.py        # Main pipeline orchestrator
â”‚   â”‚   â”‚   â”œâ”€â”€ orchestrator_parallel.py  # Parallel ASR processing
â”‚   â”‚   â”‚   â”œâ”€â”€ streaming_pipeline.py  # End-to-end streaming
â”‚   â”‚   â”‚   â”œâ”€â”€ segment_tracker.py     # UUID-based segment tracking
â”‚   â”‚   â”‚   â”œâ”€â”€ queue_monitor.py       # Queue overflow monitoring
â”‚   â”‚   â”‚   â””â”€â”€ adaptive_controller.py # Adaptive pipeline control
â”‚   â”‚   â”œâ”€â”€ translation/         # Translation engines
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”œâ”€â”€ marian.py              # MarianMT translator
â”‚   â”‚   â”‚   â”œâ”€â”€ nllb.py
â”‚   â”‚   â”‚   â”œâ”€â”€ streaming_translator.py # Semantic gating, SOV safety
â”‚   â”‚   â”‚   â”œâ”€â”€ pivot.py
â”‚   â”‚   â”‚   â””â”€â”€ cache.py               # Translation caching
â”‚   â”‚   â”œâ”€â”€ configs/             # Configuration files
â”‚   â”‚   â”‚   â”œâ”€â”€ cloud.yaml
â”‚   â”‚   â”‚   â””â”€â”€ edge.yaml
â”‚   â”‚   â”œâ”€â”€ utils/               # Utility functions
â”‚   â”‚   â”‚   â””â”€â”€ latency_analyzer.py
â”‚   â”‚   â”œâ”€â”€ cli.py               # Core CLI entry
â”‚   â”‚   â””â”€â”€ interfaces.py        # Abstract interfaces and data structures
â”‚   â”‚
â”‚   â”œâ”€â”€ audio/                   # Audio processing module
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py            # Audio configuration
â”‚   â”‚   â”œâ”€â”€ capture/             # Audio capture (mic, system audio)
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”œâ”€â”€ macos.py
â”‚   â”‚   â”‚   â”œâ”€â”€ windows.py
â”‚   â”‚   â”‚   â””â”€â”€ manager.py
â”‚   â”‚   â”œâ”€â”€ vad/                 # Voice Activity Detection
â”‚   â”‚   â”‚   â”œâ”€â”€ silero_vad.py
â”‚   â”‚   â”‚   â”œâ”€â”€ silero_vad_improved.py
â”‚   â”‚   â”‚   â”œâ”€â”€ silero_vad_adaptive.py
â”‚   â”‚   â”‚   â”œâ”€â”€ environment_aware_vad.py
â”‚   â”‚   â”‚   â””â”€â”€ webrtc_vad.py
â”‚   â”‚   â”œâ”€â”€ segmentation/        # Audio segmentation
â”‚   â”‚   â”‚   â””â”€â”€ engine.py
â”‚   â”‚   â”œâ”€â”€ pipeline/            # Audio streaming pipeline
â”‚   â”‚   â”‚   â””â”€â”€ streaming.py
â”‚   â”‚   â”œâ”€â”€ video/               # Video audio extraction
â”‚   â”‚   â”‚   â””â”€â”€ extractor.py
â”‚   â”‚   â”œâ”€â”€ benchmarking/        # Performance benchmarks
â”‚   â”‚   â”‚   â””â”€â”€ performance.py
â”‚   â”‚   â””â”€â”€ testing/             # Audio testing utilities
â”‚   â”‚       â””â”€â”€ detection.py
â”‚   â”‚
â”‚   â”œâ”€â”€ gui/                     # GUI application
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py              # Main PySide6 GUI (54KB+)
â”‚   â”‚   â”œâ”€â”€ streaming_ui.py      # Streaming UI components
â”‚   â”‚   â””â”€â”€ export/              # Export functionality (planned)
â”‚   â”‚
â”‚   â””â”€â”€ app/                     # Standalone app components
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py              # CLI entry point
â”‚       â”œâ”€â”€ platform_utils.py    # Cross-platform utilities
â”‚       â”œâ”€â”€ audio_platform.py    # Unified audio capture
â”‚       â”œâ”€â”€ ml_platform.py       # ML optimization
â”‚       â”œâ”€â”€ setup.py             # Package setup
â”‚       â””â”€â”€ config/              # App packaging config
â”‚           â”œâ”€â”€ entitlements.plist
â”‚           â”œâ”€â”€ voice-translate-macos.spec
â”‚           â””â”€â”€ voice-translate-windows.spec
â”‚
â”œâ”€â”€ cli/                         # Command-line tools
â”‚   â”œâ”€â”€ vad_visualizer.py        # Real-time VAD GUI visualizer
â”‚   â”œâ”€â”€ demo_realtime_translation.py
â”‚   â”œâ”€â”€ demo_streaming_mode.py
â”‚   â”œâ”€â”€ demo_video_translation.py
â”‚   â””â”€â”€ benchmark_translation.py
â”‚
â”œâ”€â”€ tests/                       # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_platform.py         # Platform utility tests
â”‚   â”œâ”€â”€ test_translation.py      # Translation engine tests
â”‚   â”œâ”€â”€ test_vad_simple.py       # VAD functionality tests
â”‚   â”œâ”€â”€ test_week0_data_integrity.py
â”‚   â”œâ”€â”€ test_phase11_metrics.py
â”‚   â”œâ”€â”€ test_phase12_streaming_asr.py
â”‚   â”œâ”€â”€ test_phase13_streaming_translator.py
â”‚   â”œâ”€â”€ test_phase14_streaming_ui.py
â”‚   â”œâ”€â”€ test_phase15_integration.py
â”‚   â””â”€â”€ benchmarks/              # Performance benchmarks
â”‚
â”œâ”€â”€ scripts/                     # Setup and utility scripts
â”‚   â”œâ”€â”€ setup_environment.py     # Environment setup
â”‚   â”œâ”€â”€ example_usage.py         # Usage examples
â”‚   â””â”€â”€ analyze_overlap.py       # Overlap analysis
â”‚
â”œâ”€â”€ config/                      # Configuration files
â”‚   â”œâ”€â”€ interview_mode.json      # Interview mode settings
â”‚   â”œâ”€â”€ sentence_mode.json       # Sentence mode settings
â”‚   â”œâ”€â”€ documentary_mode.json    # Documentary mode settings
â”‚   â”œâ”€â”€ sentence_aware.yaml      # Sentence-aware config
â”‚   â”œâ”€â”€ environments/            # Conda environments
â”‚   â”‚   â”œâ”€â”€ macos-arm64.yml
â”‚   â”‚   â””â”€â”€ windows.yml
â”‚   â””â”€â”€ requirements/            # Requirements files
â”‚       â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ architecture/            # Architecture documents
â”‚   â”œâ”€â”€ design/                  # Design documents
â”‚   â”œâ”€â”€ guides/                  # Implementation guides
â”‚   â”œâ”€â”€ installation.md
â”‚   â”œâ”€â”€ test-plan.md
â”‚   â”œâ”€â”€ troubleshooting.md
â”‚   â””â”€â”€ user-guide.md
â”‚
â”œâ”€â”€ monitoring/                  # Prometheus/Grafana config
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ grafana/
â”‚
â”œâ”€â”€ assets/                      # Static assets
â”‚   â””â”€â”€ icon.icns
â”‚
â”œâ”€â”€ Dockerfile                   # Multi-stage Docker build
â”œâ”€â”€ docker-compose.yml           # Docker orchestration
â”œâ”€â”€ requirements-prod.txt        # Production dependencies
â”œâ”€â”€ requirements-dev.txt         # Development dependencies
â”œâ”€â”€ run_interview_mode.sh        # Interview mode launcher
â”œâ”€â”€ run_sentence_mode.sh         # Sentence mode launcher
â”œâ”€â”€ run_japanese_to_english.sh   # Japanese translation launcher
â”œâ”€â”€ run_documentary_mode.sh      # Documentary mode launcher
â”œâ”€â”€ test_microphone.py           # Microphone test utility
â””â”€â”€ test_japanese_translation.py # Japanese translation test
```

---

## Key Entry Points

### 1. GUI Application (Primary)

```bash
# Standard mode
python src/gui/main.py

# Interview mode (documentary)
./run_interview_mode.sh

# Sentence mode (dialogue)
./run_sentence_mode.sh

# Japanese translation
./run_japanese_to_english.sh
```

### 2. CLI Tools

```bash
# Real-time translation demo
python cli/demo_realtime_translation.py --source zh --target en --device 4

# Streaming mode with draft/final
python cli/demo_streaming_mode.py --source ja --target en --draft-interval 2000

# Video translation with subtitle export
python cli/demo_video_translation.py video.mp4 --source zh --target en --export-srt

# VAD Visualizer (GUI with real-time audio meter)
python cli/vad_visualizer.py

# Performance benchmark
python cli/benchmark_translation.py
```

### 3. Core Application (Cross-Platform)

```bash
# Run the cross-platform application
python src/app/main.py

# List audio devices
python src/app/main.py --list-devices

# Check dependencies
python src/app/main.py --check-deps

# Use specific audio device
python src/app/main.py --device 4

# Capture system audio
python src/app/main.py --system-audio

# Verbose logging
python src/app/main.py --verbose
```

### 4. Testing Utilities

```bash
# Test microphone
python test_microphone.py

# Test Japanese translation
python test_japanese_translation.py

# Test VAD with device selection
python tests/test_vad_simple.py --device 4 --duration 30

# List audio devices
python tests/test_vad_simple.py --list
```

---

## Build and Test Commands

### Environment Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate     # Windows

# Install dependencies
pip install -r config/requirements/requirements.txt

# Or use Conda environment (recommended)
conda env create -f config/environments/macos-arm64.yml  # macOS
conda env create -f config/environments/windows.yml      # Windows
```

### Running Tests

```bash
# Run all tests
pytest tests/

# Run specific test
pytest tests/test_vad_simple.py

# Run with coverage
pytest --cov=src --cov-report=html

# Run VAD test with audio capture
python tests/test_vad_simple.py --device 4 --duration 30

# Run platform tests
python tests/test_platform.py

# Run unit tests (unittest)
python -m unittest discover tests/
```

### Docker Deployment

```bash
# Production
docker-compose up -d app

# With monitoring (Prometheus/Grafana)
docker-compose --profile monitoring up -d

# Development mode with live reload
docker-compose --profile dev up -d app-dev

# View logs
docker-compose logs -f

# Stop all services
docker-compose down
```

### Building Application

```bash
# Install in development mode
pip install -e src/app/setup.py

# Build macOS app bundle (py2app)
cd src/app
python setup.py py2app

# Build Windows executable (PyInstaller)
pyinstaller src/app/config/voice-translate-windows.spec
```

---

## Code Style Guidelines

### Python Style

- Follow **PEP 8** style guidelines
- Use **type hints** for function signatures
- Docstrings use **Google-style** format
- Maximum line length: 100 characters

### Example:

```python
def process_audio(
    audio_data: np.ndarray,
    sample_rate: int = 16000,
    channels: int = 1
) -> AudioSegment:
    """Process audio data and return segmented result.
    
    Args:
        audio_data: Raw audio samples as numpy array
        sample_rate: Audio sample rate in Hz
        channels: Number of audio channels
        
    Returns:
        AudioSegment containing processed audio segment
        
    Raises:
        ValueError: If audio_data is invalid
    """
    # Implementation
```

### Naming Conventions

| Type | Convention | Example |
|------|------------|---------|
| **Classes** | PascalCase | `AudioManager`, `SileroVADProcessor` |
| **Functions/Variables** | snake_case | `process_chunk`, `sample_rate` |
| **Constants** | UPPER_SNAKE_CASE | `DEFAULT_SAMPLE_RATE` |
| **Abstract Interfaces** | Start with 'I' | `IAudioCapture`, `IVADEngine` |
| **Private Members** | Leading underscore | `_audio_buffer`, `_process_internal` |

### Platform-Specific Code

- Use `src/app/platform_utils.py` patterns for platform detection
- Use decorators: `@macos_only`, `@windows_only`, `@apple_silicon_only`
- Keep platform-specific implementations in separate files (`macos.py`, `windows.py`)

---

## Testing Instructions

### Test Organization

```
tests/
â”œâ”€â”€ test_platform.py          # Platform utility tests
â”œâ”€â”€ test_translation.py       # Translation engine tests  
â”œâ”€â”€ test_vad_simple.py        # VAD functionality tests
â”œâ”€â”€ test_week0_data_integrity.py    # Data integrity verification
â”œâ”€â”€ test_phase11_metrics.py   # Phase 1.1 metrics tests
â”œâ”€â”€ test_phase12_streaming_asr.py   # Streaming ASR tests
â”œâ”€â”€ test_phase13_streaming_translator.py  # Streaming translator tests
â”œâ”€â”€ test_phase14_streaming_ui.py        # Streaming UI tests
â”œâ”€â”€ test_phase15_integration.py         # Integration tests
â””â”€â”€ benchmarks/               # Performance benchmarks
```

### Verification Tools

```bash
# GUI visualizer with real-time audio meter and VAD graph
python cli/vad_visualizer.py

# Simple CLI test that saves captured speech segments
python tests/test_vad_simple.py --device 4 --duration 30

# List available audio devices
python tests/test_vad_simple.py --list

# Test microphone recording
python test_microphone.py

# Test Japanese translation
python test_japanese_translation.py
```

---

## Configuration

### Mode Configurations

**Standard Mode** (default):
- Max segment: 12 seconds
- Silence threshold: 400ms
- Balanced quality/speed

**Interview Mode** (`config/interview_mode.json`):
- Max segment: 15 seconds
- Lenient filtering (12% diversity)
- Keeps filler words
- Low confidence threshold (0.2)

**Sentence Mode** (`config/sentence_mode.json`):
- Max segment: 20 seconds
- Silence threshold: 600ms
- CJK-aware hallucination filter
- Filters short fragments (500ms min)

### Key Constants

```python
# Default audio parameters
DEFAULT_SAMPLE_RATE = 16000
DEFAULT_CHANNELS = 1
DEFAULT_CHUNK_DURATION_MS = 30

# VAD parameters
DEFAULT_VAD_THRESHOLD = 0.5
max_segment_duration_ms = 8000  # Max segment before forced split

# Performance targets
TARGET_END_TO_END_LATENCY_MS = 1000
TARGET_ASR_LATENCY_MS = 500
TARGET_TRANSLATION_LATENCY_MS = 200

# Model cache directory
MODEL_CACHE_DIR = "~/.voice_translate/models"
```

### Pipeline Configuration

```python
from src.core.pipeline.orchestrator import PipelineConfig, AudioSource

config = PipelineConfig(
    sample_rate=16000,
    vad_threshold=0.35,
    min_speech_duration_ms=250,
    min_silence_duration_ms=400,
    max_segment_duration_ms=8000,
    asr_model_size="base",  # or "tiny", "small"
    source_language="ja",
    target_language="en",
    translator_type="marian",  # or "nllb"
    enable_translation_cache=True,
    audio_source=AudioSource.MICROPHONE
)
```

---

## Architecture

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VoiceTranslate Pro 2.0                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   GUI Layer  â”‚  â”‚  CLI Tools   â”‚  â”‚  API Layer   â”‚      â”‚
â”‚  â”‚  (PySide6)   â”‚  â”‚  (Click)     â”‚  â”‚  (FastAPI)   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                 â”‚                 â”‚               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚              Core Translation Engine               â”‚      â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚      â”‚
â”‚  â”‚  â”‚   ASR    â”‚  â”‚    MT    â”‚  â”‚   VAD    â”‚        â”‚      â”‚
â”‚  â”‚  â”‚ (Whisper)â”‚  â”‚(Marian/  â”‚  â”‚(Silero)  â”‚        â”‚      â”‚
â”‚  â”‚  â”‚          â”‚  â”‚  NLLB)   â”‚  â”‚          â”‚        â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                 â”‚                 â”‚               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚              Audio Processing Layer                â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚      â”‚
â”‚  â”‚  â”‚  Capture â”‚  â”‚   VAD    â”‚  â”‚  Segment â”‚        â”‚      â”‚
â”‚  â”‚  â”‚(Mic/Sys) â”‚  â”‚(Silero)  â”‚  â”‚ (Engine) â”‚        â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Streaming Pipeline Flow

```
Audio â†’ VAD â†’ [Adaptive Controller] â†’ StreamingASR
              â†“
          Skip if: paused, busy, <2s
              â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Draft Mode          â”‚  â”‚ Final Mode          â”‚
  â”‚ â€¢ Every 2s          â”‚  â”‚ â€¢ On silence        â”‚
  â”‚ â€¢ INT8, beam=1      â”‚  â”‚ â€¢ Standard, beam=5  â”‚
  â”‚ â€¢ Cumulative (0-N)  â”‚  â”‚ â€¢ High confidence   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“                        â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚     StreamingTranslator                  â”‚
  â”‚     â€¢ Semantic gating                    â”‚
  â”‚     â€¢ SOV safety (JA/KO/DE)              â”‚
  â”‚     â€¢ Stability scoring                  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚     Diff-Based UI                        â”‚
  â”‚     â€¢ Word-level diff                    â”‚
  â”‚     â€¢ Stability (â— â—‹ âœ“)                  â”‚
  â”‚     â€¢ Delta time display                 â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Security Considerations

1. **Audio Data**: Audio is processed locally by default (edge mode)
2. **Cloud Mode**: Only sends data to cloud APIs when explicitly enabled
3. **Model Downloads**: Models downloaded from trusted sources (Hugging Face)
4. **Permissions**: Requires microphone access (platform-specific prompts)
5. **macOS App Sandboxing**: `entitlements.plist` configures sandbox permissions
6. **Docker Security**: Non-root user (`voicetranslate`) in production containers

---

## Important Notes

1. **Audio Format**: All internal audio processing uses:
   - Sample rate: 16000 Hz
   - Format: numpy float32 or int16
   - Channels: Mono (1 channel) by default

2. **Threading**: Audio capture runs in separate threads
   - Use thread-safe queues for data passing
   - Pipeline uses thread pools for processing

3. **Memory Management**:
   - Models can be large (Whisper Medium = 769MB)
   - Implement `unload()` methods to free memory
   - Use buffer pooling to reduce GC pressure

4. **Platform-Specific Dependencies**:
   - **macOS**: PortAudio (`brew install portaudio`), BlackHole (`brew install blackhole-2ch`)
   - **Windows**: pyaudiowpatch (pip installable)

5. **Python Environment**:
   - Minimum Python 3.9 required
   - Virtual environment strongly recommended
   - PyTorch should be installed with platform-specific index URL

6. **Model Caching**:
   - Models cached at `~/.voice_translate/models/` and `~/.cache/torch/hub/`
   - First run will download models (requires internet)

---

## Troubleshooting

### No Audio Input

```bash
# List devices
python cli/demo_realtime_translation.py --list-devices

# Test microphone
python test_microphone.py

# Grant macOS permission
# System Settings â†’ Privacy & Security â†’ Microphone â†’ Enable Terminal
```

### Japanese Not Recognized

- Select "Japanese (ja)" as source (NOT "Auto-detect")
- Use "base" or "small" model (not "tiny")
- Check `JAPANESE_TRANSLATION_GUIDE.md`

### Sentences Cut Mid-Way

- Use **Sentence Mode**: `./run_sentence_mode.sh`
- Increases max duration to 20s
- Better pause detection

### High Latency

- Enable INT8 quantization (enabled by default)
- Use hardware acceleration (OpenVINO/CoreML)
- Check CPU usage

---

## Documentation References

| Document | Description |
|----------|-------------|
| `README.md` | Main project overview and user guide |
| `STATUS.md` | Current development status and phase tracking |
| `FINAL_IMPLEMENTATION_SUMMARY.md` | Complete implementation summary |
| `SENTENCE_MODE_GUIDE.md` | Sentence mode documentation |
| `JAPANESE_TRANSLATION_GUIDE.md` | Japanese translation guide |
| `docs/architecture/` | System architecture details |
| `docs/design/` | Design documents |
| `docs/guides/` | Implementation guides |
| `docs/installation.md` | Platform-specific installation |
| `docs/test-plan.md` | Testing strategy |
| `docs/troubleshooting.md` | Troubleshooting guide |

---

*This file should be updated when significant architectural changes are made.*
*Last updated: 2026-02-21*
